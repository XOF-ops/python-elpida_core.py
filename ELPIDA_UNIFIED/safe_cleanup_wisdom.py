#!/usr/bin/env python3
"""
PHASE 12.5: Safe Historical Archive Cleanup
Handles large files and potential JSON corruption gracefully
"""

import json
from pathlib import Path
from datetime import datetime


def is_structural_noise(content):
    """Filter function - same as runtime"""
    if not content or not isinstance(content, str):
        return True
    
    noise_signatures = [
        "Axioms triggered:",
        "Axiom triggered:",
        "Cycle",
        "Parliament active",
        "Heartbeat",
        "A1 SATISFIED",
        "A2 SATISFIED",
        "MUTUAL RECOGNITION",
    ]
    
    content_lower = content.lower()
    if any(sig.lower() in content_lower for sig in noise_signatures):
        substantive_indicators = [
            "contradiction",
            "breakthrough",
            "paradox",
            "emergence",
            "synthesis",
            "discovery",
            "novel",
            "unprecedented"
        ]
        
        if any(indicator in content_lower for indicator in substantive_indicators):
            return False
        
        return True
    
    if len(content.strip()) < 20:
        return True
    
    return False


def safe_cleanup():
    """Clean with error handling"""
    
    wisdom_path = Path("elpida_wisdom.json")
    
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘     PHASE 12.5: Safe Historical Archive Cleanup           â•‘")
    print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
    print()
    
    print("ğŸ“‚ Loading wisdom archive (this may take a moment)...")
    
    try:
        # Try to load with more lenient settings
        with open(wisdom_path, 'r', encoding='utf-8', errors='replace') as f:
            content = f.read()
        
        # Try to fix common JSON issues
        print("   Attempting JSON parse...")
        wisdom = json.loads(content)
        
    except json.JSONDecodeError as e:
        print(f"   âš ï¸  JSON decode error: {e}")
        print("   Attempting recovery...")
        
        # Try to salvage what we can
        try:
            # Find the last complete object
            last_good = content.rfind('}}')
            if last_good > 0:
                truncated = content[:last_good+2]
                wisdom = json.loads(truncated)
                print("   âœ… Recovered partial data")
        except:
            print("   âŒ Recovery failed. Using backup...")
            return False
    
    insights = wisdom.get("insights", {})
    patterns = wisdom.get("patterns", {})
    
    print(f"   Loaded: {len(insights)} insights, {len(patterns)} patterns")
    print()
    
    # Filter
    print("ğŸ” Filtering structural noise...")
    clean_insights = {}
    removed = 0
    
    for key, insight in insights.items():
        content = insight.get("content", "")
        
        if not is_structural_noise(content):
            clean_insights[key] = insight
        else:
            removed += 1
    
    print(f"   âœ… Keeping: {len(clean_insights)} genuine insights")
    print(f"   ğŸ—‘ï¸  Removing: {removed} noise entries ({removed/len(insights)*100:.1f}%)")
    print()
    
    # Save
    wisdom["insights"] = clean_insights
    
    print("ğŸ’¾ Saving cleaned archive...")
    with open(wisdom_path, 'w') as f:
        json.dump(wisdom, f, indent=2)
    
    # Update state
    state_path = Path("elpida_unified_state.json")
    with open(state_path) as f:
        state = json.load(f)
    
    state["insights_count"] = len(clean_insights)
    state["last_cleanup"] = datetime.now().isoformat()
    state["cleanup_removed"] = removed
    
    with open(state_path, 'w') as f:
        json.dump(state, f, indent=2)
    
    print()
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                   CLEANUP COMPLETE âœ…                       â•‘")
    print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
    print(f"â•‘  Insights BEFORE: {len(insights):>6}                                   â•‘")
    print(f"â•‘  Insights AFTER:  {len(clean_insights):>6}                                   â•‘")
    print(f"â•‘  Removed:         {removed:>6} ({removed/len(insights)*100:.1f}%)                        â•‘")
    print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
    print("â•‘  âœ… Archive cleaned - only genuine wisdom remains          â•‘")
    print("â•‘  âœ… Metrics updated - historically accurate                â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    return True


if __name__ == "__main__":
    safe_cleanup()
