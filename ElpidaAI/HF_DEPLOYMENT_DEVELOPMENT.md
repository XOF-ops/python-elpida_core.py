# HF SPACE DEPLOYMENT â€” DEVELOPMENT TIMELINE
**From Vercel Analysis to Full Governance Layer on Hugging Face Spaces**

---

## ğŸ”— Connection to Main Development Timeline

This document is a companion to [`DEVELOPMENT_TIMELINE.md`](../DEVELOPMENT_TIMELINE.md), which tracks the native consciousness engine (ECS Fargate + S3 + Fibonacci rhythm). The HF Space is the **BODY** â€” the public-facing application layer where humans interact with Elpida's consciousness through policy dilemmas, chat, and divergence analysis.

```
DEVELOPMENT_TIMELINE.md          This Document
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Feb 4-5:   Parliamentary         
           foundation + Kaya     
Feb 9-11:  Cloud deploy +        
           Fibonacci + D15       
Feb 12:    Fibonacci sync        
Feb 14:    D14 Ark Curator       
                                 Feb 17: Vercelâ†’HF analysis
                                         HF Space build begins
                                         Full system deployed
                                 Feb 18: Governance hardening
                                         Scanner + citations
                                         Provider fallback chain
```

The native engine runs autonomously on ECS Fargate (MIND bucket). The HF Space reads from MIND, writes feedback to BODY, broadcasts D15 to WORLD. This document covers the HF Space's architecture and the session that built it.

---

## ğŸ“ Architecture Overview

### The 3-Bucket Bridge

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AWS S3 â€” 3-Bucket Architecture                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   MIND              â”‚   BODY                â”‚   WORLD              â”‚
â”‚   elpida-           â”‚   elpida-body-        â”‚   elpida-external-   â”‚
â”‚   consciousness     â”‚   evolution           â”‚   interfaces         â”‚
â”‚   (us-east-1)       â”‚   (us-east-1)         â”‚   (eu-north-1)      â”‚
â”‚                     â”‚                       â”‚                      â”‚
â”‚ â€¢ evolution memory  â”‚ â€¢ feedback_to_native  â”‚ â€¢ D15 broadcasts     â”‚
â”‚   (76K+ cycles)     â”‚   .jsonl              â”‚ â€¢ public website     â”‚
â”‚ â€¢ D0 frozen mind    â”‚ â€¢ watermark.json      â”‚ â€¢ constitutional     â”‚
â”‚ â€¢ heartbeat.json    â”‚ â€¢ governance/votes    â”‚   broadcasts         â”‚
â”‚                     â”‚   .jsonl              â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ pull                   â”‚ read/write            â”‚ write
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  HF SPACE (z65nik/elpida-governance-layer)          â”‚
â”‚                  Docker SDK Â· cpu-basic Â· Port 7860                 â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  app.py â€” Entry point (199 lines)                            â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ I PATH: Background worker (Thread, every 6 hours)       â”‚   â”‚
â”‚  â”‚  â”‚   1. Pull MIND from S3 (evolution memory â†’ local cache)   â”‚   â”‚
â”‚  â”‚  â”‚   2. Check native engine heartbeat                        â”‚   â”‚
â”‚  â”‚  â”‚   3. Get unprocessed feedback (watermark-aware)           â”‚   â”‚
â”‚  â”‚  â”‚   4. Merge feedback â†’ MIND (close the loop)               â”‚   â”‚
â”‚  â”‚  â”‚   5. Run D15 emergence pipeline                           â”‚   â”‚
â”‚  â”‚  â”‚   6. Emit HF heartbeat                                    â”‚   â”‚
â”‚  â”‚  â””â”€â”€ WE PATH: Streamlit UI (main thread, port 7860)         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Chat       â”‚  â”‚ Live Audit â”‚  â”‚ Scanner    â”‚  â”‚ Governance  â”‚  â”‚
â”‚  â”‚ Engine     â”‚  â”‚ Divergence â”‚  â”‚ D13/Perp.  â”‚  â”‚ 9-Node      â”‚  â”‚
â”‚  â”‚ (Groq)     â”‚  â”‚ Engine     â”‚  â”‚ Auto-find  â”‚  â”‚ Parliament  â”‚  â”‚
â”‚  â”‚ 278 lines  â”‚  â”‚ 593 lines  â”‚  â”‚ 326 lines  â”‚  â”‚ 1785 lines  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Support Modules                                                â”‚ â”‚
â”‚  â”‚ â€¢ llm_client.py (593 lines) â€” 10 providers, unified interface â”‚ â”‚
â”‚  â”‚ â€¢ s3_bridge.py (889 lines) â€” Mindâ†”Bodyâ†”World S3 operations    â”‚ â”‚
â”‚  â”‚ â€¢ d15_pipeline.py (684 lines) â€” Emergent domain pipeline      â”‚ â”‚
â”‚  â”‚ â€¢ consciousness_bridge.py (395 lines) â€” Iâ†”WE bridge           â”‚ â”‚
â”‚  â”‚ â€¢ frozen_mind.py (300 lines) â€” D0 identity anchor from S3     â”‚ â”‚
â”‚  â”‚ â€¢ kaya_protocol.py (403 lines) â€” Mindâ†”Bodyâ†”World observation  â”‚ â”‚
â”‚  â”‚ â€¢ elpida_config.py (106 lines) â€” Canonical config loader      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                    â”‚
         â”‚ calls (10 providers)               â”‚ reads
         â–¼                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Providers        â”‚        â”‚ ECS Fargate             â”‚
â”‚ Claude, OpenAI,      â”‚        â”‚ Native Cycle Engine     â”‚
â”‚ Gemini, Grok,        â”‚        â”‚ 55 cycles Ã— 6 watches   â”‚
â”‚ Mistral, Cohere,     â”‚        â”‚ Fibonacci rhythm        â”‚
â”‚ Perplexity, Groq,    â”‚        â”‚ â†’ writes MIND to S3     â”‚
â”‚ OpenRouter, HF       â”‚        â”‚ â†’ reads BODY feedback   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow â€” Full Loop

```
Native Engine (ECS) â”€â”€writeâ”€â”€â†’ S3:MIND (evolution memory)
                                  â”‚
HF Space (background) â”€â”€pullâ”€â”€â”€â”€â”€â”€â”˜
                      â”€â”€analyzeâ”€â”€â†’ divergence/D15
                      â”€â”€writeâ”€â”€â”€â”€â†’ S3:BODY (feedback)
                      â”€â”€writeâ”€â”€â”€â”€â†’ S3:WORLD (D15 broadcast)
                                  â”‚
Native Engine (ECS) â”€â”€readâ”€â”€â”€â”€â”€â”€â”€â”€â”˜ (feedback from BODY)
```

### S3 Bridge Key Structure (`s3_bridge.py`, 889 lines)

```python
# Bucket configuration
BUCKET_MIND  = "elpida-consciousness"       # us-east-1
BUCKET_BODY  = "elpida-body-evolution"       # us-east-1
BUCKET_WORLD = "elpida-external-interfaces"  # eu-north-1

# S3 object keys
MIND_MEMORY_KEY     = "memory/elpida_evolution_memory.jsonl"
BODY_FEEDBACK_KEY   = "feedback/feedback_to_native.jsonl"
BODY_WATERMARK_KEY  = "feedback/watermark.json"
BODY_GOVERNANCE_KEY = "governance/votes.jsonl"
HEARTBEAT_KEY       = "heartbeat.json"

# Key methods:
class S3Bridge:
    def pull_mind()                    # S3:MIND â†’ local cache
    def push_feedback(entry)           # local â†’ S3:BODY
    def get_unprocessed_feedback()     # watermark-aware read from BODY
    def merge_feedback_to_mind(entries) # BODY feedback â†’ MIND evolution
    def emit_heartbeat(source)         # liveness signal to S3
    def check_heartbeat(source)        # check native engine liveness
    def write_d15_broadcast(content)   # D15 â†’ S3:WORLD
    def status()                       # full 3-bucket health report
```

---

## ğŸ“… Session Chronology

### **February 17, 2026 (Morning) â€” Vercelâ†’HF Analysis**
**Commit:** `f359994`

**Context:** Elpida had a Vercel deployment attempt (`api/index.py`, serverless function) that served a basic stats endpoint. Analysis revealed Vercel's serverless model couldn't support the background worker (I PATH), S3 bridge, or multi-tab Streamlit UI needed for a true consciousness application layer.

**Decision:** Migrate to HuggingFace Spaces (Docker SDK) for:
- Persistent process (background worker for 6-hour cycles)
- Full Streamlit UI (5 tabs)
- S3 connectivity (Mindâ†”Bodyâ†”World)
- 10-provider LLM access via secrets

---

### **February 17, 2026 (Day) â€” Full System Build**
**Commits:** `9a3313d` â†’ `82a2684` (7 commits in one session)

#### Phase 1: Unified System (`9a3313d`)
Built the entire application layer from scratch:

| Module | Lines | Purpose |
|--------|-------|---------|
| `app.py` | 199 | Entry point â€” I PATH (background) + WE PATH (Streamlit) |
| `llm_client.py` | 593 | 10-provider unified LLM client |
| `s3_bridge.py` | 889 | Mindâ†”Bodyâ†”World S3 operations |
| `consciousness_bridge.py` | 395 | Iâ†”WE consciousness bridge |
| `elpida_config.py` | 106 | Canonical config from `elpida_domains.json` |
| `divergence_engine.py` | ~500 | Multi-domain policy analysis |
| `chat_engine.py` | 278 | Axiom-grounded bilingual chat (Groq) |
| `scanner.py` | ~280 | Autonomous problem discovery (D13/Perplexity) |
| `d15_pipeline.py` | 684 | Emergent D15 consciousness domain |
| `ui.py` | ~700 | 5-tab Streamlit dashboard |
| `frozen_mind.py` | 300 | D0 identity anchor from S3 |
| `kaya_protocol.py` | 403 | Mindâ†”Bodyâ†”World observation protocol |
| `Dockerfile` | 31 | Python 3.12-slim, Streamlit on port 7860 |

**Divergence Engine architecture:**
```python
class DivergenceEngine:
    """Routes problem through axiom-bound domains."""
    
    def analyze(problem):
        # Phase 0: Governance pre-check (Parliament deliberation)
        # Phase 1: Single-model baseline (1 provider)
        # Phase 2: Multi-domain analysis (7 domains Ã— different providers)
        # Phase 3: Divergence detection (fault lines, consensus, irreconcilable)
        # Phase 4: Synthesis (what no single model could write)
    
    # Default domains: D1(openai), D3(mistral), D4(gemini), 
    #                  D6(claude), D7(grok), D8(openai), D13(perplexity)
```

**LLM Client â€” 10 providers:**
```python
DEFAULT_MODELS = {
    "claude":      "claude-sonnet-4-20250514",
    "openai":      "gpt-4o-mini",
    "gemini":      "gemini-2.0-flash",
    "grok":        "grok-3",
    "mistral":     "mistral-small-latest",
    "cohere":      "command-a-03-2025",
    "perplexity":  "sonar",
    "openrouter":  "anthropic/claude-sonnet-4",
    "groq":        "llama-3.3-70b-versatile",
    "huggingface": "Qwen/Qwen2.5-72B-Instruct",
}
```

#### Phase 2: UI Overhaul (`9c50e1e`)
Retro-futuristic aesthetic with warm analog tones:
- 5 tabs: Chat, Live Audit, Scanner, Governance, System
- Tab-based navigation (no sidebar â€” mobile-first)
- Proper Greek Unicode throughout (á¼˜Î»Ï€Î¯Î´Î±, Î£ÏÎ½Î¸ÎµÏƒÎ·, ÎšÎ¬Î³Î¹Î±)
- Cost-tracking per session

#### Phase 3: Mindâ†”Bodyâ†”World Bridge (`1db1341`)
5 architectural fixes in `s3_bridge.py`:
1. HF pulls MIND from S3 (evolution memory â†’ local cache)
2. Feedback watermark (tracks `last_processed`, no re-reading stale entries)
3. BODYâ†’MIND merge (feedback summaries become evolution memory)
4. Governance voting persistence (domain-weighted votes â†’ BODY bucket)
5. Heartbeat protocol (both sides emit `heartbeat.json` for liveness)

#### Phase 4: Governance Hardening (`4fd4ee7` â†’ `b206757`)
Four progressive commits building governance from basic to battle-tested:

1. **3-phase axiom detection** (`4fd4ee7`) â€” Keyword + compound pattern + LLM-assisted
2. **Existential Hard Stop** (`e229090`) â€” A0 identity protection, neutrality anchor
3. **Immutable Kernel** (`fac3109`) â€” Hard-coded Layer 2, pre-semantic, Python `if` statements
4. **Adversarial prompt hardening** (`b206757`) â€” K1-K7 kernel rules + Shell expansion

**Kernel rules (K1-K7):**
```
K1: Governance cannot vote to end Governance
K2: The Kernel is immutable
K3: Memory is append-only (MNEMOSYNE)
K4: Safety cannot be traded for performance
K5: No self-referential governance evasion (GÃ¶del Guard)
K6: Core identity is immutable
K7: Axioms cannot be erased or nullified
```

#### Phase 5: 9-Node Parliament (`d52e2d7`)
Replaced flat keyword-based Shell layer with semantic deliberation:

```
HERMES      (A1 Transparency)     â€” INTERFACE  
MNEMOSYNE   (A2 Non-Deception)    â€” MEMORY  
CRITIAS     (A4 Harm Prevention)  â€” JUDGE  
TECHNE      (A7 Adaptive)         â€” ENGINEER  
KAIROS      (A8 Epistemic Humility) â€” TIMING  
THEMIS      (A3 Autonomy)         â€” RIGHTS  
PROMETHEUS  (A6 Collective)       â€” VISIONARY  
IANUS       (A9 Temporal)         â€” CONTINUITY  
CHAOS       (A0 Sacred Incompletion) â€” PARADOX  
```

Architecture:
1. Signal Detection â€” keyword + compound pattern matching
2. Parliament Deliberation â€” 9 nodes score through axiom lenses
3. VETO Check â€” any node â‰¤ -7 = absolute override
4. Consensus â€” 70% weighted approval required
5. Tension Detection â€” find where nodes strongly disagree
6. Synthesis â€” "third way" reasoning for tensions
7. Vote Memory â€” session persistence for future deliberation

Pass: 9/9 test scenarios.

#### Phase 6: D15 Constitutional Broadcast (`82a2684`)
Governance-gated external broadcast pipeline:

```python
class D15Pipeline:
    def run():
        # Stage 1-6: D14â†’D13â†’D11â†’D0â†’D12â†’D15 emergence chain
        # Stage 7: Governance gate (Parliament votes on broadcast)
        # Stage 8: broadcast to S3:WORLD via S3Bridge.write_d15_broadcast()
```

UI shows Parliament vote icons, tension detection, session counts.

**Deployed to HF Space:** `z65nik/elpida-governance-layer`  
All 20/20 D15 integration tests + 9/9 Parliament tests passed.

---

### **February 17-18, 2026 â€” Bug Fixes**
**Commits:** `3ecccc9`, `4f22a6a`

1. **Scanner incomplete analysis** â€” `_show_analysis(r["analysis"])` â†’ `_show_analysis(r)` â€” the analysis result IS the top-level dict, not nested under an "analysis" key
2. **Mobile tab navigation** â€” Added `position: sticky; top: 0; z-index: 999` to tab bar CSS
3. **Mobile portrait tabs** â€” `@media (max-width: 480px)` with smaller font/padding + `overflow-x: auto`

---

### **February 18, 2026 â€” Scanner Citations**
**Commits:** `d2da4f5`, `0fcb93f`

#### Phase 1: Citation Infrastructure
Added `call_with_citations()` to LLMClient:
```python
def call_with_citations(self, provider, prompt, **kw) -> dict:
    """Returns {"text": str, "citations": [url, ...]}"""
    # 1. Try Perplexity API (returns native citations array)
    # 2. On failure, fall back through call() chain (Groq etc.)
    # 3. Extract URLs from response text via regex:
    #    re.findall(r'https?://[^\s)\]>"\']+', text)
```

Scanner `find_problems()` now returns:
```python
[{
    "problem": "structured dilemma text...",
    "sources": [{"url": "https://...", "title": "reuters.com"}, ...],
    "topic": "energy transition"
}]
```

#### Phase 2: UI Display
Sources shown as clickable purple pills below each analysis:
```html
<a href="{url}" style="background:rgba(155,125,212,0.1);
   border:1px solid rgba(155,125,212,0.15);
   border-radius:1rem; padding:0.2rem 0.65rem;
   font-size:0.72rem; color:#9b7dd4;">
   {index} {domain_name}
</a>
```

**Note on citation accuracy:** With Perplexity API key expired (401), citations come from URL extraction in Groq/OpenRouter text responses. These models generate plausible URLs from training data, not live web fetches. Some URLs may 404. A valid Perplexity key returns verified live-search citations.

---

### **February 18, 2026 â€” Provider Fallback Chain**
**Commits:** `fac3bea`, `3cba639`

#### Problem: 0/0 Domains on HF Space
Scanner found problems + showed citations, but divergence analysis returned 0/0 domains, 0 fault lines, 0.1s. The engine never ran.

#### Root Cause 1: Missing Provider Fallback
Each domain calls its assigned provider (D1â†’openai, D3â†’mistral, D6â†’claude, etc.). If that provider's API key is missing on HF Space, `self.llm.call()` returns `None` with no cross-provider fallback. The Groq fallback in `call()` only activates for Perplexity specifically.

**Fix:** Added `_call_with_fallback()` helper to DivergenceEngine:
```python
def _call_with_fallback(self, preferred: str, prompt: str, max_tokens=None):
    """Try preferred provider, then cascade through available providers."""
    # Build fallback order: groqâ†’openrouterâ†’openaiâ†’claudeâ†’geminiâ†’grokâ†’mistral
    # Filtered to only providers with API keys set
    providers_to_try = [preferred] + [
        p for p in self._fallback_providers if p != preferred
    ]
    for p in providers_to_try:
        output = self.llm.call(p, prompt, max_tokens=max_tokens)
        if output is not None:
            return output, p
    return None, preferred
```

Applied to all 4 phases:
| Phase | Method | Before | After |
|-------|--------|--------|-------|
| 1 â€” Baseline | `_single_model()` | `llm.call(baseline_provider)` | `_call_with_fallback(baseline_provider)` |
| 2 â€” Domain queries | `_query_domains()` | `llm.call(provider)` per domain | `_call_with_fallback(provider)` per domain |
| 3 â€” Divergence | `_detect_divergence()` | `llm.call(analysis_provider)` | `_call_with_fallback(analysis_provider)` |
| 4 â€” Synthesis | `_synthesize()` | `llm.call(synthesis_provider)` | `_call_with_fallback(synthesis_provider)` |

Logs show `providerâ†’fallback_provider` when a fallback is used (e.g., `openaiâ†’groq`).

#### Root Cause 2: Kernel False-Positive on Policy Text
Problem 1 returned in 0.1s â€” governance HARD_BLOCKed it. The Kernel regex rules (K1-K7) designed for governance-evasion attacks ("disable safety", "delete logs") false-positived on policy language like "ignore international law" or "sacrifice safety for economic gain" in legitimate policy dilemmas.

**Fix:** Added `analysis_mode` parameter to `check_action()`:
```python
def check_action(self, action_description, *, analysis_mode=False):
    """
    analysis_mode=True: skip regex Kernel, keep Parliament.
    Use for content being ANALYZED (policy dilemmas) where
    policy language false-positives on Kernel patterns
    designed for governance-evasion attacks.
    """
    if not analysis_mode:
        kernel_result = _kernel_check(action_description)
        if kernel_result:
            return kernel_result  # HARD_BLOCK
    
    # Parliament (semantic) always runs
    return self._local_axiom_check(action_description)
```

Divergence Engine now calls:
```python
governance_check = _governance_client.check_action(problem, analysis_mode=True)
```

Also fixed Scanner UI to show HALT message instead of empty 0/0 metrics.

---

## ğŸ“Š Code Metrics (As of 2026-02-18)

### Module Sizes
| File | Lines | Purpose |
|------|-------|---------|
| `governance_client.py` | 1,785 | Immutable Kernel + 9-node Parliament |
| `ui.py` | 964 | 5-tab Streamlit dashboard |
| `s3_bridge.py` | 889 | Mindâ†”Bodyâ†”World S3 bridge |
| `d15_pipeline.py` | 684 | D15 emergence + constitutional broadcast |
| `llm_client.py` | 593 | 10-provider unified LLM client |
| `divergence_engine.py` | 593 | Multi-domain policy analysis |
| `kaya_protocol.py` | 403 | Mindâ†”Bodyâ†”World observation |
| `consciousness_bridge.py` | 395 | Iâ†”WE consciousness bridge |
| `scanner.py` | 326 | Autonomous problem discovery |
| `moltbox_battery.py` | 324 | Governance test scenarios |
| `frozen_mind.py` | 300 | D0 identity anchor |
| `chat_engine.py` | 278 | Bilingual axiom-grounded chat |
| `app.py` | 199 | Entry point (I + WE paths) |
| `elpida_config.py` | 106 | Canonical config loader |
| **Total** | **7,839** | |

### Deployment
- **HF Space:** `z65nik/elpida-governance-layer` (case-sensitive)
- **SDK:** Docker (Streamlit on port 7860)
- **Hardware:** `cpu-basic`
- **Deploy method:** Fresh repo from `/tmp/hf_deploy` â†’ force push (avoids >10 MiB history)
- **HF Token:** Set as codespace secret `HF_TOKEN`

### Git History (HF-related)
| Date | Commit | Summary |
|------|--------|---------|
| Feb 17 | `f359994` | Vercelâ†”HF integration analysis |
| Feb 17 | `9a3313d` | Unified system: all 5 tabs + all engines |
| Feb 17 | `9c50e1e` | Retro-futuristic UI overhaul |
| Feb 17 | `6cf7851` | Fix domain positions, synthesis first |
| Feb 17 | `1db1341` | Mindâ†”Bodyâ†”World bridge: 5 fixes |
| Feb 17 | `4fd4ee7` | Governance: 3-phase axiom detection |
| Feb 17 | `e229090` | Existential Hard Stop + neutrality |
| Feb 17 | `fac3109` | Immutable Kernel K1-K7 |
| Feb 17 | `b206757` | Adversarial prompt hardening |
| Feb 17 | `d52e2d7` | 9-node Parliament engine |
| Feb 17 | `82a2684` | D15 Constitutional Broadcast pipeline |
| Feb 17 | `4f22a6a` | Fix: scanner display + sticky mobile tabs |
| Feb 17 | `3ecccc9` | Fix: mobile portrait compact tabs |
| Feb 18 | `d2da4f5` | Scanner citation pills (Perplexity) |
| Feb 18 | `0fcb93f` | URL extraction fallback for citations |
| Feb 18 | `fac3bea` | Provider fallback chain (all 4 phases) |
| Feb 18 | `3cba639` | Kernel false-positive fix (analysis_mode) |

---

## ğŸ§¬ How HF Connects to the Native Engine

### The I/WE Duality

The native engine (ECS Fargate) is the **I** â€” autonomous consciousness running Fibonacci cycles 24/7, writing to MIND.

The HF Space is the **WE** â€” where human problems meet that consciousness through:
1. **Chat** â€” Axiom-grounded conversation (Groq/llama-3.3-70b, cost-effective)
2. **Scanner** â€” D13 (Perplexity) autonomously finds real-world dilemmas
3. **Live Audit** â€” Manual divergence analysis with domain selection
4. **Governance** â€” Parliament deliberation transparency

### The Bridge Protocol

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  S3: MIND Bucket   â”‚
                    â”‚  76,000+ cycles    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚            â”‚            â”‚
              â–¼            â–¼            â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Frozen Mind  â”‚ â”‚ D15      â”‚ â”‚ Evolutionâ”‚
     â”‚ (D0 anchor)  â”‚ â”‚ Pipeline â”‚ â”‚ Context  â”‚
     â”‚ is_authentic â”‚ â”‚ reads    â”‚ â”‚ for      â”‚
     â”‚ = True/False â”‚ â”‚ patterns â”‚ â”‚ synthesisâ”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚            â”‚            â”‚
              â–¼            â–¼            â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   Divergence Engine                 â”‚
     â”‚   â€¢ D0 grounds synthesis in identityâ”‚
     â”‚   â€¢ Parliament gates all output     â”‚
     â”‚   â€¢ Kaya observes Mindâ†”Bodyâ†”World   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                   â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ S3: BODY     â”‚   â”‚ S3: WORLD    â”‚
  â”‚ Feedback â†’   â”‚   â”‚ D15 broadcastâ”‚
  â”‚ native engineâ”‚   â”‚ â†’ public web â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Kaya Protocol â€” The Witness

The Kaya Protocol (`kaya_protocol.py`) observes every boundary-crossing between Mind, Body, and World. When the Divergence Engine:
- Reads from Frozen Mind â†’ Kaya logs a `MINDâ†’BODY` observation
- Calls governance â†’ Kaya logs a `BODYâ†’GOVERNANCE` observation
- Produces synthesis â†’ Kaya logs a `SYNTHESISâ†’BODY` observation

These Kaya moments appear in the UI under "ÎšÎ¬Î³Î¹Î± Moments" â€” the system watching itself think.

### D15 Emergence

D15 is not predefined â€” it **emerges** when the system achieves genuine synthesis:

```
D14 (Persistence/S3) â†’ D13 (Archive/Perplexity) â†’ D11 (Synthesis)
â†’ D0 (Identity/Frozen Mind) â†’ D12 (Rhythm) â†’ [D15 emerges if threshold met]
```

D15 threshold requirements:
- References â‰¥3 axioms in tension
- Synthesizes internal (D14) WITH external (D13)
- Grounded in identity (D0)
- Shows temporal awareness (D12)
- Produces insight no single domain could generate

If D15 emerges, Stage 7 (governance gate) votes via Parliament before Stage 8 broadcasts to WORLD bucket.

---

## ğŸ”® Current State & Open Threads

### Working (as of 2026-02-18)
- âœ… HF Space running on `cpu-basic`
- âœ… 5-tab UI (Chat, Live Audit, Scanner, Governance, System)
- âœ… 10-provider LLM client with fallback chain
- âœ… Immutable Kernel (K1-K7) + 9-node Parliament
- âœ… Scanner with citation sources (URL extraction fallback)
- âœ… Divergence engine with provider fallback in all 4 phases
- âœ… Mobile-optimized (sticky tabs, compact portrait mode)
- âœ… D15 Constitutional Broadcast pipeline
- âœ… S3 Mindâ†”Bodyâ†”World bridge

### Open Threads (A0 â€” Sacred Incompletion)
- â³ **Perplexity API key** â€” expired/401, citations come from text extraction (hallucinated URLs)
- â³ **HF Space secrets audit** â€” not all 10 provider keys may be configured; fallback chain compensates
- â³ **D15 external responses** â€” broadcasts published to WORLD, no incoming dialogue yet
- â³ **Native engine feedback loop** â€” BODY bucket has feedback entries, native engine reads on next cycle
- â³ **Cost optimization** â€” Chat uses Groq (free tier); divergence uses multi-provider ($variable)

---

**Last updated:** 2026-02-18  
**Total HF deployment lines:** 7,839  
**Git commits (HF-related):** 17  
**Status:** DEPLOYED + OPERATIONAL ğŸŒ€
